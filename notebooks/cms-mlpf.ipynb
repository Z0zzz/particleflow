{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-consortium",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import matplotlib\n",
    "import scipy\n",
    "import mplhep as hep\n",
    "\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-offense",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(arr):\n",
    "    return arr.reshape((arr.shape[0]*arr.shape[1], arr.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-symphony",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cms_label(x0=0.12, x1=0.23, x2=0.67, y=0.90):\n",
    "    plt.figtext(x0, y,'CMS',fontweight='bold', wrap=True, horizontalalignment='left', fontsize=12)\n",
    "    plt.figtext(x1, y,'Simulation Preliminary', style='italic', wrap=True, horizontalalignment='left', fontsize=10)\n",
    "    plt.figtext(x2, y,'Run 3 (14 TeV), $\\mathrm{t}\\overline{\\mathrm{t}}$ events',  wrap=False, horizontalalignment='left', fontsize=10)\n",
    "\n",
    "def sample_label(ax, x=0.03, y=0.98):\n",
    "    plt.text(x, y, \"$\\mathrm{t}\\overline{\\mathrm{t}}$ events\", va=\"top\", ha=\"left\", size=10, transform=ax.transAxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-zambia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_thresholds_f(ypred_raw_f, thresholds):\n",
    "    msk = np.ones_like(ypred_raw_f)\n",
    "    for i in range(len(thresholds)):\n",
    "        msk[:, i] = ypred_raw_f[:, i]>thresholds[i]\n",
    "    ypred_id_f = np.argmax(ypred_raw_f*msk, axis=-1)\n",
    "    return ypred_id_f\n",
    "\n",
    "def apply_thresholds(ypred_raw, thresholds):\n",
    "    msk = np.ones_like(ypred_raw)\n",
    "    for i in range(len(thresholds)):\n",
    "        msk[:, :, i] = ypred_raw[:, :, i]>thresholds[i]\n",
    "    ypred_id = np.argmax(ypred_raw*msk, axis=-1)\n",
    "    return ypred_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_names = {\n",
    "    1: \"ch.had\",\n",
    "    2: \"n.had\",\n",
    "    3: \"HFEM\",\n",
    "    4: \"HFHAD\",\n",
    "    5: \"g\",\n",
    "    6: \"el\",\n",
    "    7: \"mu\"\n",
    "}\n",
    "\n",
    "pid_names_long = {\n",
    "    1: \"charged hadrons\",\n",
    "    2: \"neutral hadrons\",\n",
    "    3: \"HFEM\",\n",
    "    4: \"HFHAD\",\n",
    "    5: \"photons\",\n",
    "    6: \"electrons\",\n",
    "    7: \"muons\"\n",
    "}\n",
    "\n",
    "var_names = {\n",
    "    1: \"charge\",\n",
    "    2: \"pt\",\n",
    "    3: \"eta\",\n",
    "    4: \"sin phi\",\n",
    "    5: \"cos phi\",\n",
    "    6: \"energy\"\n",
    "}\n",
    "\n",
    "x_labels = [\n",
    "    \"track\", \"PS1\", \"PS2\", \"ECAL\", \"HCAL\", \"GSF\", \"BREM\", \"HFEM\", \"HFHAD\", \"SC\", \"HO\"\n",
    "]\n",
    "y_labels = [pid_names[i] for i in range(1,8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../experiments/cms-gnn-dense-2cc4e7f9.gpu0.local/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-shield",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = []\n",
    "ygens = []\n",
    "ycands = []\n",
    "ypreds = []\n",
    "ypreds_raw = []\n",
    "for fi in glob.glob(path + \"/pred*.npz\"):\n",
    "    dd = np.load(fi)\n",
    "    Xs.append(dd[\"X\"])\n",
    "    ygens.append(dd[\"ygen\"])\n",
    "    ycands.append(dd[\"ycand\"])\n",
    "    ypreds.append(dd[\"ypred\"])\n",
    "    ypreds_raw.append(dd[\"ypred_raw\"])\n",
    "\n",
    "X = np.concatenate(Xs)\n",
    "ygen = np.concatenate(ygens)\n",
    "ycand = np.concatenate(ycands)\n",
    "ypred = np.concatenate(ypreds)\n",
    "ypred_raw = np.concatenate(ypreds_raw)\n",
    "\n",
    "X_f = X.reshape((X.shape[0]*X.shape[1], X.shape[2]))\n",
    "msk_X = X_f[:, 0]!=0\n",
    "ygen_f = ygen.reshape((ygen.shape[0]*ygen.shape[1], ygen.shape[2]))\n",
    "ycand_f = ycand.reshape((ycand.shape[0]*ycand.shape[1], ycand.shape[2]))\n",
    "ypred_f = ypred.reshape((ypred.shape[0]*ypred.shape[1], ypred.shape[2]))\n",
    "ypred_raw_f = ypred_raw.reshape((ypred_raw.shape[0]*ypred_raw.shape[1], ypred_raw.shape[2]))\n",
    "\n",
    "#ad-hoc correction factors\n",
    "thresholds = np.array([0.0, 0.4, 0.63, 0.5, 0.57, 0.15, 0.98, 0.75])\n",
    "ypred_id = apply_thresholds(ypred_raw, thresholds)\n",
    "ypred_id_f = apply_thresholds_f(ypred_raw_f, thresholds)\n",
    "\n",
    "ypred[ypred_id==3, 6] *= 1.7\n",
    "ypred[ypred_id==4, 6] *= 0.7\n",
    "\n",
    "ypred_f[ypred_id_f==3, 6] *= 1.7\n",
    "ypred_f[ypred_id_f==4, 6] *= 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-acquisition",
   "metadata": {},
   "outputs": [],
   "source": [
    "msk_f = X_f[:, 0]!=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.accuracy_score(ycand_f[msk_f, 0], ypred_id_f[msk_f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-moses",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.balanced_accuracy_score(ycand_f[msk_f, 0], ypred_id_f[msk_f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-serum",
   "metadata": {},
   "outputs": [],
   "source": [
    "for icls in range(1,8):\n",
    "    npred = np.sum(ypred_id == icls, axis=1)\n",
    "    ncand = np.sum(ycand[:, :, 0] == icls, axis=1)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(ncand, npred, marker=\".\", alpha=0.8)\n",
    "    a = 0.5*min(np.min(npred), np.min(ncand))\n",
    "    b = 1.5*max(np.max(npred), np.max(ncand))\n",
    "    plt.xlim(a,b)\n",
    "    plt.ylim(a,b)\n",
    "    plt.plot([a,b],[a,b], color=\"black\", ls=\"--\")\n",
    "    plt.title(pid_names_long[icls],y=1.05)\n",
    "    plt.xlabel(\"number of PFCandidates\")\n",
    "    plt.ylabel(\"number of MLPFCandidates\")\n",
    "    cms_label(x2=0.6, y=0.89)\n",
    "    plt.savefig(\"num_cls{}.pdf\".format(icls))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-chile",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_history(path, max_epoch=None):\n",
    "    ret = {}\n",
    "    for fi in glob.glob(path):\n",
    "        data = json.load(open(fi))\n",
    "        epoch = int(fi.split(\"_\")[-1].split(\".\")[0])\n",
    "        ret[epoch] = data\n",
    "    \n",
    "    if not max_epoch:\n",
    "        max_epoch = max(ret.keys())\n",
    "    ret2 = []\n",
    "    for i in range(max_epoch):\n",
    "        ret2.append(ret[i])\n",
    "    return pandas.DataFrame(ret2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-substitute",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = load_history(path + \"/history_*.json\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "plt.plot(history[\"loss\"], label=\"train\")\n",
    "plt.plot(history[\"val_loss\"], label=\"test\")\n",
    "#plt.yscale(\"log\")\n",
    "#plt.xlim(50,500)\n",
    "plt.ylim(history[\"val_loss\"].values[-1]*0.9, history[\"val_loss\"].values[-1]*1.1)\n",
    "plt.legend(loc=\"best\", frameon=False)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Total loss\")\n",
    "cms_label()\n",
    "sample_label(ax, x=0.03, y=0.10)\n",
    "plt.savefig(\"loss.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "plt.plot(history[\"cls_loss\"], label=\"train\")\n",
    "plt.plot(history[\"val_cls_loss\"], label=\"test\")\n",
    "#plt.yscale(\"log\")\n",
    "#plt.xlim(50,500)\n",
    "plt.ylim(history[\"val_cls_loss\"].values[-1]*0.9, history[\"val_cls_loss\"].values[-1]*1.1)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Classification loss\")\n",
    "cms_label()\n",
    "sample_label(ax, x=0.03, y=0.10)\n",
    "plt.savefig(\"cls_loss.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-carol",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "plt.plot(history[\"energy_loss\"], label=\"train\")\n",
    "plt.plot(history[\"val_energy_loss\"], label=\"test\")\n",
    "#plt.yscale(\"log\")\n",
    "#plt.xlim(50,500)\n",
    "plt.ylim(history[\"val_energy_loss\"].values[-1]*0.9, history[\"val_energy_loss\"].values[-1]*1.1)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Energy loss\")\n",
    "cms_label(x1=0.2, x2=0.6)\n",
    "plt.savefig(\"energy_loss.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-consideration",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "plt.plot(history[\"pt_loss\"], label=\"train\")\n",
    "plt.plot(history[\"val_pt_loss\"], label=\"test\")\n",
    "#plt.yscale(\"log\")\n",
    "#plt.xlim(50,500)\n",
    "plt.ylim(history[\"val_pt_loss\"].values[-1]*0.9, history[\"val_pt_loss\"].values[-1]*1.1)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Pt loss\")\n",
    "cms_label(x1=0.2, x2=0.6)\n",
    "plt.savefig(\"pt_loss.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history[\"sin_phi_loss\"], label=\"train\")\n",
    "plt.plot(history[\"val_sin_phi_loss\"], label=\"test\")\n",
    "#plt.yscale(\"log\")\n",
    "#plt.xlim(50,500)\n",
    "plt.ylim(history[\"val_sin_phi_loss\"].values[-1]*0.9, history[\"val_sin_phi_loss\"].values[-1]*1.1)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"sin phi loss\")\n",
    "cms_label(x1=0.2, x2=0.6)\n",
    "plt.savefig(\"sin_phi_loss.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "plt.plot(history[\"cos_phi_loss\"], label=\"train\")\n",
    "plt.plot(history[\"val_cos_phi_loss\"], label=\"test\")\n",
    "#plt.yscale(\"log\")\n",
    "#plt.xlim(50,500)\n",
    "plt.ylim(history[\"val_cos_phi_loss\"].values[-1]*0.9, history[\"val_cos_phi_loss\"].values[-1]*1.1)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"cos phi loss\")\n",
    "cms_label(x1=0.2, x2=0.6)\n",
    "plt.savefig(\"cos_phi_loss.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-chest",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "plt.plot(history[\"eta_loss\"], label=\"train\")\n",
    "plt.plot(history[\"val_eta_loss\"], label=\"test\")\n",
    "#plt.yscale(\"log\")\n",
    "#plt.xlim(50,500)\n",
    "plt.ylim(history[\"val_eta_loss\"].values[-1]*0.9, history[\"val_eta_loss\"].values[-1]*1.1)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"eta loss\")\n",
    "cms_label(x1=0.2, x2=0.6)\n",
    "plt.savefig(\"eta_loss.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "plt.plot(history[\"charge_loss\"], label=\"train\")\n",
    "plt.plot(history[\"val_charge_loss\"], label=\"test\")\n",
    "#plt.yscale(\"log\")\n",
    "#plt.xlim(50,500)\n",
    "plt.ylim(history[\"val_charge_loss\"].values[-1]*0.9, history[\"val_charge_loss\"].values[-1]*1.1)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"charge loss\")\n",
    "cms_label(x1=0.2, x2=0.6)\n",
    "plt.savefig(\"charge_loss.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-graduation",
   "metadata": {},
   "outputs": [],
   "source": [
    "for icls in range(1,8):\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes()\n",
    "    msk = (ycand_f[:, 0] == icls)\n",
    "    plt.hist(ypred_raw_f[msk & (X_f[:, 0] != 0), icls], bins=100, density=1, histtype=\"step\", lw=2, color=\"blue\", label=\"true \"+pid_names[icls]);\n",
    "    plt.hist(ypred_raw_f[~msk & (X_f[:, 0] != 0), icls], bins=100, density=1, histtype=\"step\", lw=2, color=\"red\", label=\"other particles\");\n",
    "    plt.axvline(thresholds[icls], 0, 0.7, ls=\"--\",\n",
    "        color=\"black\", label=\"threshold: {:.2f}\".format(thresholds[icls]), lw=1)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.title(\"Particle reconstruction for {}\".format(pid_names[icls]), y=1.05)\n",
    "    plt.xlabel(\"Classification output {}\".format(icls))\n",
    "    plt.ylabel(\"Normalized number of particles [a.u.]\")\n",
    "    plt.legend(loc=2, frameon=False)\n",
    "    plt.ylim(1e-2, 1e4)\n",
    "    cms_label(x1=0.2, x2=0.6)\n",
    "    plt.savefig(\"cls_output_{}.pdf\".format(icls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perm = np.random.permutation(ycand_f[msk_X].shape[0])[:100000]\n",
    "\n",
    "cm_norm = sklearn.metrics.confusion_matrix(\n",
    "    ycand_f[msk_X, 0],\n",
    "    ypred_id_f[msk_X],\n",
    "    labels=range(8),\n",
    "    normalize=\"true\"\n",
    ")\n",
    "\n",
    "cm = sklearn.metrics.confusion_matrix(\n",
    "    ycand_f[msk_X, 0],\n",
    "    ypred_id_f[msk_X],\n",
    "    labels=range(8),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "ax = plt.axes()\n",
    "plt.imshow(cm_norm[1:, 1:], cmap=\"Blues\")\n",
    "plt.colorbar()\n",
    "\n",
    "cms_label(x1=0.18, x2=0.52, y=0.82)\n",
    "#sample_label(ax, x=0.8, y=1.0)\n",
    "plt.xticks(range(len(y_labels)), y_labels);\n",
    "plt.yticks(range(len(y_labels)), y_labels);\n",
    "plt.xlabel(\"Predicted PFCandidate\")\n",
    "plt.ylabel(\"True PFCandidate\")\n",
    "plt.title(\"MLPF trained on PF\", y=1.03)\n",
    "#plt.tight_layout()\n",
    "plt.savefig(\"cm_normed.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-haven",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "ax = plt.axes()\n",
    "plt.imshow(cm[1:, 1:], cmap=\"Blues\")\n",
    "plt.colorbar()\n",
    "\n",
    "cms_label(x1=0.18, x2=0.52, y=0.82)\n",
    "#sample_label(ax, x=0.8, y=1.0)\n",
    "plt.xticks(range(len(y_labels)), y_labels);\n",
    "plt.yticks(range(len(y_labels)), y_labels);\n",
    "plt.xlabel(\"Predicted PFCandidate\")\n",
    "plt.ylabel(\"True PFCandidate\")\n",
    "plt.title(\"MLPF trained on PF\", y=1.03)\n",
    "plt.savefig(\"cm.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = {\n",
    "    2: np.linspace(0,100,100),\n",
    "    3: np.linspace(-8,8,100),\n",
    "    4: np.linspace(-1,1,100),\n",
    "    5: np.linspace(-1,1,100),\n",
    "    6: np.linspace(0,500,100),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "for icls in range(1,8):\n",
    "    for ivar in range(2,7):\n",
    "        plt.figure()\n",
    "        ax = plt.axes()\n",
    "        b = bins[ivar]\n",
    "        #plt.hist(ygen_f[ygen_f[:, 0]==icls, ivar], bins=b, histtype=\"step\", lw=2, label=\"gen\");\n",
    "        plt.hist(ycand_f[ycand_f[:, 0]==icls, ivar], bins=b, histtype=\"step\", lw=2, label=\"PF\");\n",
    "        plt.hist(ypred_f[ypred_id_f==icls, ivar], bins=b, histtype=\"step\", lw=2, label=\"MLPF\");\n",
    "        plt.yscale(\"log\")\n",
    "        plt.legend()\n",
    "        plt.title(pid_names_long[icls], y=1.05)\n",
    "        plt.xlabel(var_names[ivar])\n",
    "        plt.ylabel(\"Number of particles\")\n",
    "        cms_label(x1=0.2, x2=0.6)\n",
    "        plt.savefig(\"distribution_icls{}_ivar{}.pdf\".format(icls, ivar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-motion",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(7, 6, figsize=(6*6,7*5))\n",
    "\n",
    "for axs, icls in zip(axes, range(1,8)):    \n",
    "    axes = axs.flatten()\n",
    "    \n",
    "    npred = np.sum(ypred_id == icls, axis=1)\n",
    "    ncand = np.sum(ycand[:, :, 0] == icls, axis=1)\n",
    "    ngen = np.sum(ygen[:, :, 0] == icls, axis=1)\n",
    "    \n",
    "    a = 0.5*min(np.min(npred), np.min(ncand))\n",
    "    b = 1.5*max(np.max(npred), np.max(ncand))\n",
    "    \n",
    "    axes[0].scatter(ncand, npred, marker=\".\")\n",
    "    \n",
    "    axes[0].set_xlim(a,b)\n",
    "    axes[0].set_ylim(a,b)\n",
    "    axes[0].plot([a,b],[a,b], color=\"black\", ls=\"--\")\n",
    "    axes[0].set_title(pid_names[icls])\n",
    "    axes[0].set_xlabel(\"number of PFCandidates\")\n",
    "    axes[0].set_ylabel(\"number of MLPFCandidates\")\n",
    "    \n",
    "    msk_both = (ycand_f[:, 0]==icls) & (ypred_id_f==icls)\n",
    "    print(icls, np.sum(msk_both))\n",
    "\n",
    "    for ivar, ax in zip([2,3,4,5,6], axes[1:]):\n",
    "        \n",
    "        hist = np.histogram2d(\n",
    "            ycand_f[msk_both, ivar],\n",
    "            ypred_f[msk_both, ivar], bins=(bins[ivar], bins[ivar])\n",
    "        )\n",
    "        norm = matplotlib.colors.Normalize(vmin=0, vmax=max(10, np.max(hist[0])))\n",
    "        if ivar == 2 or ivar == 6:\n",
    "            norm =  matplotlib.colors.LogNorm(vmin=1, vmax=max(10, 10*np.max(hist[0])))\n",
    "        hep.hist2dplot(\n",
    "            hist, cmap=\"Blues\",\n",
    "            norm=norm,\n",
    "            ax=ax\n",
    "        )\n",
    "        ax.plot([bins[ivar][0],bins[ivar][-1]], [bins[ivar][0], bins[ivar][-1]], color=\"black\", ls=\"--\")\n",
    "        ax.set_title(\"pred. {}, {}\".format(pid_names[icls], var_names[ivar]))\n",
    "        ax.set_xlabel(\"true value (PFCandidate)\")\n",
    "        ax.set_ylabel(\"reconstructed value (MLPF)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"full_performance.pdf\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
