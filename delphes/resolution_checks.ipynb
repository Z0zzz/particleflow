{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import uproot_methods\n",
    "import networkx as nx\n",
    "import glob\n",
    "from matplotlib.colors import LogNorm\n",
    "import pandas\n",
    "import json\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import bz2\n",
    "import mpl_toolkits\n",
    "import mplhep as hep\n",
    "\n",
    "plt.style.use(hep.style.ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midpoints(x):\n",
    "    return x[:-1] + np.diff(x)/2\n",
    "\n",
    "def mask_empty(hist):\n",
    "    h0 = hist[0].astype(np.float64)\n",
    "    h0[h0<50] = 0\n",
    "    return (h0, hist[1])\n",
    "\n",
    "def divide_zero(a, b):\n",
    "    a = a.astype(np.float64)\n",
    "    b = b.astype(np.float64)\n",
    "    out = np.zeros_like(a)\n",
    "    np.divide(a, b, where=b>0, out=out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p plots\n",
    "\n",
    "#Raw input data\n",
    "!wget --no-clobber https://zenodo.org/record/4452283/files/tev14_pythia8_ttbar_0_0.pkl.bz2\n",
    "    \n",
    "#predictions file\n",
    "!wget --no-clobber https://jpata.web.cern.ch/jpata/particleflow/pythia8_ttbar/pred.npz.bz2\n",
    "\n",
    "#timing file\n",
    "!wget --no-clobber https://jpata.web.cern.ch/jpata/particleflow/pythia8_ttbar/synthetic_timing.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw a single event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(bz2.BZ2File(\"tev14_pythia8_ttbar_0_0.pkl.bz2\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have a set 100 of events in one file\n",
    "len(data[\"ycand\"]), len(data[\"ygen\"]), len(data[\"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each event, we have a number of input elements (X)\n",
    "# 0-padded arrays of the target particles from generator (ygen) and from the baseline algo (ycand)\n",
    "data[\"X\"][0].shape, data[\"ygen\"][0].shape, data[\"ycand\"][0].shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"X\"][0]\n",
    "ycand = data[\"ycand\"][0]\n",
    "ygen = data[\"ygen\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input element feature vector, defined in ntuplizer.py:make_tower_array,make_track_array:\n",
    "# tower: (type, Et, eta, sin phi, cos phi, E, Eem, Ehad)\n",
    "# track: (type, pt, eta, sin phi, cos phi, P, eta_outer, sin phi_outer, cos phi_outer, charge, is_gen_muon, is_gen_electron)\n",
    "X[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get masks for the tracks, ECAL and HCAL elements\n",
    "msk_trk = X[:, 0] == 2\n",
    "msk_ecal = (X[:, 0] == 1) & (X[:, 6] > 0)\n",
    "msk_hcal = (X[:, 0] == 1) & (X[:, 7] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_trk = pandas.DataFrame(X[msk_trk], columns=[\"id\", \"pt\", \"eta\", \"sphi\", \"cphi\", \"p\", \"eta_outer\", \"sphi_outer\", \"cphi_outer\", \"charge\", \"is_gen_muon\", \"is_gen_ele\"])\n",
    "arr_ecal = pandas.DataFrame(X[msk_ecal][:, :6], columns=[\"id\", \"et\", \"eta\", \"sphi\", \"cphi\", \"e\"])\n",
    "arr_hcal = pandas.DataFrame(X[msk_hcal][:, :6], columns=[\"id\", \"et\", \"eta\", \"sphi\", \"cphi\", \"e\"])\n",
    "\n",
    "arr_gen = pandas.DataFrame(ygen[ygen[:, 0]!=0], columns=[\"id\", \"charge\", \"pt\", \"eta\", \"sphi\", \"cphi\", \"energy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute track x,y on the inner and outer surfaces\n",
    "points_a = arr_trk[\"eta\"].values, np.arctan2(arr_trk[\"sphi\"], arr_trk[\"cphi\"]).values\n",
    "points_b = arr_trk[\"eta_outer\"].values, np.arctan2(arr_trk[\"sphi_outer\"], arr_trk[\"cphi_outer\"]).values\n",
    "\n",
    "r1 = 0.5\n",
    "r2 = 1.0\n",
    "r3 = 1.2\n",
    "r4 = 1.4\n",
    "r5 = 1.6\n",
    "\n",
    "points = []\n",
    "for i in range(len(arr_trk)):\n",
    "    point = []\n",
    "    point.append((0,0,0))\n",
    "    point.append((points_a[0][i], r1*np.sin(points_a[1][i]), r1*np.cos(points_a[1][i])))\n",
    "    point.append((points_b[0][i], r2*np.sin(points_b[1][i]), r2*np.cos(points_b[1][i])))\n",
    "    points.append(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,10))\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "lc = mpl_toolkits.mplot3d.art3d.Line3DCollection(points, linewidths=0.2, color=\"gray\", alpha=0.5)\n",
    "ax.add_collection(lc)\n",
    "# just for better legend\n",
    "lc2 = mpl_toolkits.mplot3d.art3d.Line3DCollection([], linewidths=2, color=\"gray\", alpha=0.5, label=\"Tracks\")\n",
    "ax.add_collection(lc2)\n",
    "\n",
    "ax.scatter(arr_ecal[\"eta\"], r3*arr_ecal[\"sphi\"], r3*arr_ecal[\"cphi\"], s=0.1*arr_ecal[\"e\"], color=u'#1f77b4', marker=\"s\", alpha=0.5)\n",
    "ax.scatter(arr_hcal[\"eta\"], r4*arr_hcal[\"sphi\"], r4*arr_hcal[\"cphi\"], s=0.1*arr_hcal[\"e\"], color=u'#ff7f0e', marker=\"s\", alpha=0.5)\n",
    "ax.scatter(arr_gen[\"eta\"], r5*arr_gen[\"sphi\"], r5*arr_gen[\"cphi\"], alpha=0.2, marker=\"x\", color=\"red\")\n",
    "# just for better legend\n",
    "ax.scatter([],[], [], alpha=0.5, marker=\"s\", s = 50, color=u'#1f77b4', label=\"ECAL clusters\")\n",
    "ax.scatter([],[], [], alpha=0.5, marker=\"s\", s = 100, color=u'#ff7f0e', label=\"HCAL clusters\")\n",
    "ax.scatter([],[], [], alpha=0.5, marker=\"x\", s = 50, color=\"red\", label=\"Truth particles\")\n",
    "\n",
    "\n",
    "ax.set_zlabel(r\"$y$ [a.u.]\",labelpad=15)\n",
    "ax.set_ylabel(r\"$x$ [a.u.]\",labelpad=15)\n",
    "ax.set_xlabel(r\"$\\eta$\",labelpad=15)\n",
    "\n",
    "from matplotlib.ticker import MultipleLocator, AutoMinorLocator\n",
    "ax.xaxis.set_major_locator(MultipleLocator(2))\n",
    "ax.yaxis.set_major_locator(MultipleLocator(1))\n",
    "ax.zaxis.set_major_locator(MultipleLocator(1))\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(1))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.5))\n",
    "ax.zaxis.set_minor_locator(MultipleLocator(0.5))\n",
    "\n",
    "ax.xaxis._axinfo[\"grid\"].update({\"linewidth\":0.2, \"color\" : \"gray\", \"which\":\"major\", \"linestyle\":\"--\",\"alpha\":0.1})\n",
    "ax.yaxis._axinfo[\"grid\"].update({\"linewidth\":0.2, \"color\" : \"gray\", \"which\":\"major\", \"linestyle\":\"--\",\"alpha\":0.1})\n",
    "ax.zaxis._axinfo[\"grid\"].update({\"linewidth\":0.2, \"color\" : \"gray\", \"which\":\"major\", \"linestyle\":\"--\",\"alpha\":0.1})\n",
    "\n",
    "ax.w_xaxis.set_pane_color((1.0, 1.0, 1.0, 1.0))\n",
    "ax.w_yaxis.set_pane_color((1.0, 1.0, 1.0, 1.0))\n",
    "ax.w_zaxis.set_pane_color((1.0, 1.0, 1.0, 1.0))\n",
    "\n",
    "legend = plt.legend(title =r\"$t\\overline{t}$, 14 TeV, 200 PU\",frameon=False, bbox_to_anchor=(0.92, 1.0), loc='upper left',fontsize=20)\n",
    "plt.setp(legend.get_title(),fontsize=22)\n",
    "#plt.title(\"Simulated event with PU200\")\n",
    "plt.savefig(\"plots/event.pdf\", bbox_inches=\"tight\")\n",
    "plt.savefig(\"plots/event.png\", bbox_inches=\"tight\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the training is done, we can generate the pred.npz file using the following:\n",
    "```bash\n",
    "singularity exec --nv ~/HEP-KBFI/singularity/base.simg python3 ../mlpf/tensorflow/delphes_model.py --action validate --weights weights.300-*.hdf5\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the predictions file from the model (this can take a while, as the file is compressed and pretty large)\n",
    "fi = np.load(bz2.BZ2File(\"pred.npz.bz2\", \"rb\"))\n",
    "\n",
    "#if you run `bzip -d pred.npz.bz2` locally, you can use this:\n",
    "#fi = np.load(open(\"pred.npz\", \"rb\"))\n",
    "ygen = fi[\"ygen\"]\n",
    "ycand = fi[\"ycand\"]\n",
    "ypred = fi[\"ypred\"]\n",
    "X = fi[\"X\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten the events\n",
    "ygen = ygen.reshape((ygen.shape[0]*ygen.shape[1], ygen.shape[2]))\n",
    "ycand = ycand.reshape((ycand.shape[0]*ycand.shape[1], ycand.shape[2]))\n",
    "ypred = ypred.reshape((ypred.shape[0]*ypred.shape[1], ypred.shape[2]))\n",
    "X = X.reshape((X.shape[0]*X.shape[1], X.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ygen.shape)\n",
    "print(ycand.shape)\n",
    "print(ypred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.linspace(-8, 8, 61)\n",
    "\n",
    "msk_pid1 = (ygen[:, 0]==1)\n",
    "msk_pid2 = (ygen[:, 0]==2)\n",
    "msk_pid3 = (ygen[:, 0]==3)\n",
    "msk_pid4 = (ygen[:, 0]==4)\n",
    "msk_pid5 = (ygen[:, 0]==5)\n",
    "\n",
    "h1 = np.histogram(ygen[msk_pid1, 3], bins=b)\n",
    "h2 = np.histogram(ygen[msk_pid2, 3], bins=b)\n",
    "h3 = np.histogram(ygen[msk_pid3, 3], bins=b)\n",
    "h4 = np.histogram(ygen[msk_pid4, 3], bins=b)\n",
    "h5 = np.histogram(ygen[msk_pid5, 3], bins=b)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "xs = midpoints(h1[1])\n",
    "width = np.diff(h1[1])\n",
    "\n",
    "plt.bar(xs, h5[0], width=width, label=\"Muons (N={:.1E})\".format(np.sum(msk_pid5)))\n",
    "plt.bar(xs, h4[0], width=width, bottom=h5[0], label=\"Electrons (N={:.1E})\".format(np.sum(msk_pid4)))\n",
    "plt.bar(xs, h3[0], width=width, bottom=h4[0] + h5[0], label=\"Photons (N={:.1E})\".format(np.sum(msk_pid3)))\n",
    "plt.bar(xs, h2[0], width=width, bottom=h3[0] + h4[0] + h5[0], label=\"Neutral hadrons (N={:.1E})\".format(np.sum(msk_pid2)))\n",
    "plt.bar(xs, h1[0], width=width, bottom=h2[0] + h3[0] + h4[0] + h5[0], label=\"Charged hadrons (N={:.1E})\".format(np.sum(msk_pid1)))\n",
    "plt.legend(loc=\"best\", frameon=False)\n",
    "plt.yscale(\"log\")\n",
    "plt.ylim(1e1, 1e10)\n",
    "plt.xlabel(\"Truth particle $\\eta$\")\n",
    "plt.ylabel(\"Truth particles\")\n",
    "plt.savefig(\"plots/gen_eta.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.linspace(0, 100, 61)\n",
    "\n",
    "msk_pid1 = (ygen[:, 0]==1)\n",
    "msk_pid2 = (ygen[:, 0]==2)\n",
    "msk_pid3 = (ygen[:, 0]==3)\n",
    "msk_pid4 = (ygen[:, 0]==4)\n",
    "msk_pid5 = (ygen[:, 0]==5)\n",
    "\n",
    "h1 = np.histogram(ygen[msk_pid1, 2], bins=b)\n",
    "h2 = np.histogram(ygen[msk_pid2, 2], bins=b)\n",
    "h3 = np.histogram(ygen[msk_pid3, 2], bins=b)\n",
    "h4 = np.histogram(ygen[msk_pid4, 2], bins=b)\n",
    "h5 = np.histogram(ygen[msk_pid5, 2], bins=b)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "xs = midpoints(h1[1])\n",
    "width = np.diff(h1[1])\n",
    "\n",
    "plt.bar(xs, h5[0], width=width, label=\"Muons (N={:.1E})\".format(np.sum(msk_pid5)))\n",
    "plt.bar(xs, h4[0], width=width, bottom=h5[0], label=\"Electrons (N={:.1E})\".format(np.sum(msk_pid4)))\n",
    "plt.bar(xs, h3[0], width=width, bottom=h4[0] + h5[0], label=\"Photons (N={:.1E})\".format(np.sum(msk_pid3)))\n",
    "plt.bar(xs, h2[0], width=width, bottom=h3[0] + h4[0] + h5[0], label=\"Neutral hadrons (N={:.1E})\".format(np.sum(msk_pid2)))\n",
    "plt.bar(xs, h1[0], width=width, bottom=h2[0] + h3[0] + h4[0] + h5[0], label=\"Charged hadrons (N={:.1E})\".format(np.sum(msk_pid1)))\n",
    "\n",
    "plt.legend(loc=\"best\", frameon=False)\n",
    "plt.yscale(\"log\")\n",
    "plt.ylim(1e1, 1e9)\n",
    "plt.xlabel(r\"Truth particle $p_\\mathrm{T}$ [GeV]\")\n",
    "plt.ylabel(\"Truth particles\")\n",
    "plt.savefig(\"plots/gen_pt.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = {\n",
    "    \"pt\": np.linspace(0, 10, 61),\n",
    "    \"eta\": np.linspace(-5, 5, 61),\n",
    "    \"sphi\": np.linspace(-1, 1, 61),\n",
    "    \"cphi\": np.linspace(-1, 1, 61),\n",
    "    \"energy\": np.linspace(0, 100, 61)\n",
    "}\n",
    "\n",
    "pid_names = {\n",
    "    1: \"Charged hadrons\",\n",
    "    2: \"Neutral hadrons\",\n",
    "    3: \"Photons\",\n",
    "    4: \"Electrons\",\n",
    "    5: \"Muons\",\n",
    "}\n",
    "var_names = {\n",
    "    \"pt\": r\"$p_\\mathrm{T}$ [GeV]\",\n",
    "    \"eta\": r\"$\\eta$\",\n",
    "    \"sphi\": r\"$\\mathrm{sin} \\phi$\",\n",
    "    \"cphi\": r\"$\\mathrm{cos} \\phi$\",\n",
    "    \"energy\": r\"$E$ [GeV]\"\n",
    "}\n",
    "\n",
    "var_names_nounit = {\n",
    "    \"pt\": r\"$p_\\mathrm{T}$\",\n",
    "    \"eta\": r\"$\\eta$\",\n",
    "    \"sphi\": r\"$\\mathrm{sin} \\phi$\",\n",
    "    \"cphi\": r\"$\\mathrm{cos} \\phi$\",\n",
    "    \"energy\": r\"$E$\"\n",
    "}\n",
    "\n",
    "var_names_bare = {\n",
    "    \"pt\": \"p_\\mathrm{T}\",\n",
    "    \"eta\": \"\\eta\",\n",
    "    \"energy\": \"E\",\n",
    "}\n",
    "\n",
    "\n",
    "var_indices = {\n",
    "    \"pt\": 2,\n",
    "    \"eta\": 3,\n",
    "    \"sphi\": 4,\n",
    "    \"cphi\": 5,\n",
    "    \"energy\": 6\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_num_particles_pid(pid, ax=None):\n",
    "    if not ax:\n",
    "        plt.figure(figsize=(4,4))\n",
    "        ax = plt.axes()\n",
    "        \n",
    "    x1 = np.sum(fi[\"ygen\"][:, :, 0]==pid, axis=1)\n",
    "    x2 = np.sum(fi[\"ypred\"][:, :, 0]==pid, axis=1)\n",
    "    x3 = np.sum(fi[\"ycand\"][:, :, 0]==pid, axis=1)\n",
    "\n",
    "    v0 = np.min([np.min(x1), np.min(x2), np.min(x3)])\n",
    "    v1 = np.max([np.max(x1), np.max(x2), np.max(x3)])\n",
    "\n",
    "    #draw only a random sample of the events to avoid overcrowding\n",
    "    inds = np.random.permutation(len(x1))[:1000]\n",
    "    \n",
    "    ax.scatter(\n",
    "        x1[inds],\n",
    "        x3[inds],\n",
    "        marker=\"o\",\n",
    "        label=\"Rule-based PF (r={:.4f})\".format(np.corrcoef(x1, x3)[0,1]),\n",
    "        alpha=0.5\n",
    "    )\n",
    "\n",
    "    ax.scatter(\n",
    "        x1[inds],\n",
    "        x2[inds],\n",
    "        marker=\"^\",\n",
    "        label=\"MLPF (r={:.4f})\".format(np.corrcoef(x1, x2)[0,1]),\n",
    "        alpha=0.5\n",
    "    )\n",
    "    leg = ax.legend(loc=\"best\", frameon=False, title=pid_names[pid])\n",
    "    for lh in leg.legendHandles: \n",
    "        lh.set_alpha(1)\n",
    "    ax.plot([v0, v1], [v0, v1], color=\"black\", ls=\"--\")\n",
    "    #ax.set_title(pid_names[pid])\n",
    "    ax.set_xlabel(\"Truth particles / event\")\n",
    "    ax.set_ylabel(\"Reconstructed particles / event\")\n",
    "    #plt.title(\"Particle multiplicity, {}\".format(pid_names[pid]))\n",
    "    #plt.savefig(\"plots/num_particles_pid{}.pdf\".format(pid), bbox_inches=\"tight\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 2*8))\n",
    "plot_num_particles_pid(1, ax1)\n",
    "plot_num_particles_pid(2, ax2)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/num_particles.pdf\")\n",
    "plt.savefig(\"plots/num_particles.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for pid in [1,2,3,4,5]:\n",
    "#     for var in [\"pt\", \"eta\", \"sphi\", \"cphi\", \"energy\"]:\n",
    "#         rng = ranges[var]\n",
    "\n",
    "#         msk = (ygen[:, 0]==pid) & (ypred[:, 0]==pid) & (ycand[:, 0]==pid)\n",
    "\n",
    "#         plt.figure(figsize=(6,5))\n",
    "#         plt.title(pid_names[pid])\n",
    "#         plt.hist2d(\n",
    "#             ygen[msk, var_indices[var]],\n",
    "#             ypred[msk, var_indices[var]],\n",
    "#             bins=(rng, rng),\n",
    "#             cmap=\"Blues\",\n",
    "#             norm=matplotlib.colors.LogNorm()\n",
    "#         )\n",
    "#         plt.colorbar()\n",
    "#         plt.xlabel(\"Gen {}\".format(var_names[var]))\n",
    "#         plt.ylabel(\"MLPF {}\".format(var_names[var]))\n",
    "#         plt.savefig(\"plots/corr_mlpf_pid{}_{}.pdf\".format(pid, var), bbox_inches=\"tight\")\n",
    "\n",
    "#         plt.figure(figsize=(6,5))\n",
    "#         plt.title(pid_names[pid])\n",
    "#         plt.hist2d(\n",
    "#             ygen[msk, var_indices[var]],\n",
    "#             ycand[msk, var_indices[var]],\n",
    "#             bins=(rng, rng),\n",
    "#             cmap=\"Blues\",\n",
    "#             norm=matplotlib.colors.LogNorm()\n",
    "#         );\n",
    "#         plt.xlabel(\"Gen {}\".format(var_names[var]))\n",
    "#         plt.ylabel(\"DelphesPF {}\".format(var_names[var]))\n",
    "#         plt.colorbar()\n",
    "#         plt.savefig(\"plots/corr_delphespf_pid{}_{}.pdf\".format(pid, var), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake rate plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_efficiency_fakerate(pid, var, bins, both=True):\n",
    "    var_idx = var_indices[var]\n",
    "\n",
    "    msk_gen = ygen[:, 0]==pid\n",
    "    msk_pred = ypred[:, 0]==pid\n",
    "    msk_cand = ycand[:, 0]==pid\n",
    "\n",
    "    hist_gen = np.histogram(ygen[msk_gen, var_idx], bins=bins);\n",
    "    hist_cand = np.histogram(ygen[msk_gen & msk_cand, var_idx], bins=bins);\n",
    "    hist_pred = np.histogram(ygen[msk_gen & msk_pred, var_idx], bins=bins);\n",
    "    \n",
    "    hist_gen = mask_empty(hist_gen)\n",
    "    hist_cand = mask_empty(hist_cand)\n",
    "    hist_pred = mask_empty(hist_pred)\n",
    "\n",
    "    #efficiency plot\n",
    "    if both:\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 2*8))\n",
    "    else:\n",
    "        fig, ax1 = plt.subplots(1, 1, figsize=(8, 1*8))\n",
    "\n",
    "    #ax1.set_title(\"reco efficiency for {}\".format(pid_names[pid]))\n",
    "    ax1.errorbar(\n",
    "        midpoints(hist_gen[1]),\n",
    "        divide_zero(hist_cand[0], hist_gen[0]),\n",
    "        divide_zero(np.sqrt(hist_gen[0]), hist_gen[0]) * divide_zero(hist_cand[0], hist_gen[0]),\n",
    "        lw=0, label=\"Rule-based PF\", elinewidth=2, marker=\".\",markersize=10)\n",
    "    ax1.errorbar(\n",
    "        midpoints(hist_gen[1]),\n",
    "        divide_zero(hist_pred[0], hist_gen[0]),\n",
    "        divide_zero(np.sqrt(hist_gen[0]), hist_gen[0]) * divide_zero(hist_pred[0], hist_gen[0]),\n",
    "        lw=0, label=\"MLPF\", elinewidth=2, marker=\".\",markersize=10)\n",
    "    ax1.legend(frameon=False, loc=0, title=pid_names[pid])\n",
    "    ax1.set_ylim(0,1.2)\n",
    "    ax1.set_xlabel(var_names[var])\n",
    "    ax1.set_ylabel(\"Efficiency\")\n",
    "\n",
    "    hist_cand2 = np.histogram(ygen[msk_cand & (ygen[:, 0]!=0), var_idx], bins=bins);\n",
    "    hist_pred2 = np.histogram(ygen[msk_pred & (ygen[:, 0]!=0), var_idx], bins=bins);\n",
    "    hist_cand_gen2 = np.histogram(ygen[msk_cand & ~msk_gen & (ygen[:, 0]!=0), var_idx], bins=bins);\n",
    "    hist_pred_gen2 = np.histogram(ygen[msk_pred & ~msk_gen & (ygen[:, 0]!=0), var_idx], bins=bins);\n",
    "\n",
    "    hist_cand2 = mask_empty(hist_cand2)\n",
    "    hist_cand_gen2 = mask_empty(hist_cand_gen2)\n",
    "    hist_pred2 = mask_empty(hist_pred2)\n",
    "    hist_pred_gen2 = mask_empty(hist_pred_gen2)\n",
    "    \n",
    "    if both:\n",
    "        #fake rate plot\n",
    "        #ax2.set_title(\"reco fake rate for {}\".format(pid_names[pid]))\n",
    "        ax2.errorbar(\n",
    "            midpoints(hist_cand2[1]),\n",
    "            divide_zero(hist_cand_gen2[0], hist_cand2[0]),\n",
    "            divide_zero(np.sqrt(hist_cand_gen2[0]), hist_cand2[0]),\n",
    "            lw=0, label=\"Rule-based PF\", elinewidth=2, marker=\".\",markersize=10)\n",
    "        ax2.errorbar(\n",
    "            midpoints(hist_pred2[1]),\n",
    "            divide_zero(hist_pred_gen2[0], hist_pred2[0]),\n",
    "            divide_zero(np.sqrt(hist_pred_gen2[0]), hist_pred2[0]),\n",
    "            lw=0, label=\"MLPF\", elinewidth=2, marker=\".\",markersize=10)\n",
    "        ax2.legend(frameon=False, loc=0, title=pid_names[pid])\n",
    "        ax2.set_ylim(0, 1.0)\n",
    "        #plt.yscale(\"log\")\n",
    "        ax2.set_xlabel(var_names[var])\n",
    "        ax2.set_ylabel(\"Fake rate\")\n",
    "    \n",
    "    plt.savefig(\"plots/eff_fake_pid{}_{}.pdf\".format(pid, var))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_efficiency_fakerate(1, \"pt\", np.linspace(0, 3, 61), both=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_efficiency_fakerate(1, \"eta\", np.linspace(-3, 3, 61), both=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_efficiency_fakerate(\n",
    "    2, \"energy\", np.linspace(5, 55, 61))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_efficiency_fakerate(\n",
    "    2, \"eta\", np.linspace(-6, 6, 61)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolution plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reso(pid, var, rng, ax=None):\n",
    "    var_idx = var_indices[var]\n",
    "    msk = (ygen[:, 0]==pid) & (ypred[:, 0]==pid) & (ycand[:, 0]==pid)\n",
    "    bins = np.linspace(-rng, rng, 100)\n",
    "    yg = ygen[msk, var_idx]\n",
    "    yp = ypred[msk, var_idx]\n",
    "    yc = ycand[msk, var_idx]\n",
    "    ratio_mlpf = (yp - yg) / yg\n",
    "    ratio_dpf = (yc - yg) / yg\n",
    "    \n",
    "    #remove outliers for std value computation\n",
    "    outlier = 10\n",
    "    ratio_mlpf[ratio_mlpf<-outlier] = -outlier\n",
    "    ratio_mlpf[ratio_mlpf>outlier] = outlier\n",
    "    ratio_dpf[ratio_dpf<-outlier] = -outlier\n",
    "    ratio_dpf[ratio_dpf>outlier] = outlier\n",
    "    \n",
    "    res_dpf = np.mean(ratio_dpf), np.std(ratio_dpf)\n",
    "    res_mlpf = np.mean(ratio_mlpf), np.std(ratio_mlpf)\n",
    "    \n",
    "    if ax is None:\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        ax = plt.axes()\n",
    "        \n",
    "    #plt.title(\"{} resolution for {}\".format(var_names_nounit[var], pid_names[pid]))\n",
    "    ax.hist(ratio_dpf, bins=bins, histtype=\"step\", lw=2, label=\"Rule-based PF\\n$\\mu={:.2f},\\\\ \\sigma={:.2f}$\".format(*res_dpf));\n",
    "    ax.hist(ratio_mlpf, bins=bins, histtype=\"step\", lw=2, label=\"MLPF\\n$\\mu={:.2f},\\\\ \\sigma={:.2f}$\".format(*res_mlpf));\n",
    "    ax.legend(frameon=False, title=pid_names[pid])\n",
    "    ax.set_xlabel(\"{nounit} resolution, $({bare}^\\prime - {bare})/{bare}$\".format(nounit=var_names_nounit[var],bare=var_names_bare[var]))\n",
    "    ax.set_ylabel(\"Particles\")\n",
    "    #plt.ylim(0, ax.get_ylim()[1]*2)\n",
    "    ax.set_ylim(1, 1e10)\n",
    "    ax.set_yscale(\"log\")\n",
    "\n",
    "    return {\"dpf\": res_dpf, \"mlpf\": res_mlpf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 2*8))\n",
    "\n",
    "res_ch_had_pt = plot_reso(1, \"pt\", 2, ax=ax1)\n",
    "res_ch_had_eta = plot_reso(1, \"eta\", 0.2, ax=ax2)\n",
    "\n",
    "ax2.set_ylim(100, 10**10)\n",
    "#ax1.set_title(\"Charged hadrons\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/res_pid1.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 2*8))\n",
    "\n",
    "res_n_had_e = plot_reso(2, \"energy\", 5, ax=ax1)\n",
    "res_n_had_eta = plot_reso(2, \"eta\", 0.5, ax=ax2)\n",
    "\n",
    "#ax1.set_title(\"Neutral hadrons\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/res_pid2.pdf\")\n",
    "plt.savefig(\"plots/res_pid2.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = sklearn.metrics.confusion_matrix(\n",
    "    ygen[:, 0], ycand[:, 0], normalize=\"true\"\n",
    ")\n",
    "\n",
    "confusion2 = sklearn.metrics.confusion_matrix(\n",
    "    ygen[:, 0], ypred[:, 0], normalize=\"true\"\n",
    ")\n",
    "\n",
    "\n",
    "confusion_unnorm = sklearn.metrics.confusion_matrix(\n",
    "    ygen[:, 0], ycand[:, 0],\n",
    ")\n",
    "\n",
    "confusion2_unnorm = sklearn.metrics.confusion_matrix(\n",
    "    ygen[:, 0], ypred[:, 0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(confusion, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(confusion2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.accuracy_score(ygen[:, 0], ycand[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.accuracy_score(ygen[:, 0], ypred[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True,\n",
    "                          ax=None):\n",
    "    \"\"\"\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    cm[np.isnan(cm)] = 0.0\n",
    "\n",
    "    if not ax:\n",
    "        fig = plt.figure(figsize=(5, 4))\n",
    "        ax = plt.axes()\n",
    "    ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    #ax.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        ax.set_xticks(tick_marks)\n",
    "        ax.set_xticklabels(target_names, rotation=45)\n",
    "        ax.set_yticks(tick_marks)\n",
    "        ax.set_yticklabels(target_names, rotation=45)\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            ax.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            ax.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    ax.set_ylabel('True PID')\n",
    "    ax.set_xlabel('Reconstructed PID')\n",
    "    ax.set_xlim(-1, len(target_names))\n",
    "    ax.set_ylim(-1, len(target_names))\n",
    "    #ax.set_xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 2*8))\n",
    "\n",
    "plot_confusion_matrix(confusion, [\"None\", \"Ch. had\", \"N. had\", \"$\\gamma$\", r\"$e^\\pm$\", r\"$\\mu^\\pm$\"], ax=ax1)\n",
    "plot_confusion_matrix(confusion2, [\"None\", \"Ch. had\", \"N. had\", \"$\\gamma$\", r\"$e^\\pm$\", r\"$\\mu^\\pm$\"], ax=ax2)\n",
    "\n",
    "ax1.set_xlabel(\"\")\n",
    "ax1.set_title(\"Rule-based PF\")\n",
    "ax2.set_title(\"MLPF\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/confusion_normed.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_delphes = {\n",
    "    \"ch_had_eff\": confusion_unnorm[1, 1] / np.sum(confusion_unnorm[1, :]),\n",
    "    \"n_had_eff\": confusion_unnorm[2, 2] / np.sum(confusion_unnorm[2, :]),\n",
    "\n",
    "    \"ch_had_fake\": 1.0 - confusion_unnorm[1, 1] / np.sum(confusion_unnorm[:, 1]),\n",
    "    \"n_had_fake\": 1.0 - confusion_unnorm[2, 2] / np.sum(confusion_unnorm[:, 2]),\n",
    "    \n",
    "    \"res_ch_had_eta_s\": res_ch_had_eta[\"dpf\"][1],\n",
    "    \"res_ch_had_pt_s\": res_ch_had_pt[\"dpf\"][1],\n",
    "    \n",
    "    \"res_n_had_eta_s\": res_n_had_eta[\"dpf\"][1],\n",
    "    \"res_n_had_e_s\": res_n_had_e[\"dpf\"][1],\n",
    "}\n",
    "\n",
    "metrics_mlpf = {\n",
    "    \"ch_had_eff\": confusion2_unnorm[1, 1] / np.sum(confusion2_unnorm[1, :]),\n",
    "    \"n_had_eff\": confusion2_unnorm[2, 2] / np.sum(confusion2_unnorm[2, :]),\n",
    "\n",
    "    \"ch_had_fake\": 1.0 - confusion2_unnorm[1, 1] / np.sum(confusion2_unnorm[:, 1]),\n",
    "    \"n_had_fake\": 1.0 - confusion2_unnorm[2, 2] / np.sum(confusion2_unnorm[:, 2]),\n",
    "    \n",
    "    \n",
    "    \"res_ch_had_eta_s\": res_ch_had_eta[\"mlpf\"][1],\n",
    "    \"res_ch_had_pt_s\": res_ch_had_pt[\"mlpf\"][1],\n",
    "\n",
    "    \"res_n_had_eta_s\": res_n_had_eta[\"mlpf\"][1],\n",
    "    \"res_n_had_e_s\": res_n_had_e[\"mlpf\"][1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_delphes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_mlpf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    \"Efficiency\",\n",
    "    \"Fake rate\",\n",
    "    r\"$p_\\mathrm{T}$ ($E$) resolution\",\n",
    "    r\"$\\eta$ resolution\"\n",
    "]\n",
    "\n",
    "for n, ks in zip(names, [\n",
    "    (\"ch_had_eff\", \"n_had_eff\"),\n",
    "    (\"ch_had_fake\", \"n_had_fake\"),\n",
    "    (\"res_ch_had_pt_s\", \"res_n_had_e_s\"),\n",
    "    (\"res_ch_had_eta_s\", \"res_n_had_eta_s\")\n",
    "    ]):\n",
    "    \n",
    "    k0 = ks[0]\n",
    "    k1 = ks[1]\n",
    "    print(\"{} & {:.2f} & {:.2f} & {:.2f} & {:.2f} \\\\\\\\\".format(\n",
    "        n, metrics_delphes[k0], metrics_mlpf[k0], metrics_delphes[k1], metrics_mlpf[k1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling of the model inference time with synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scaling of the model timing is done using synthetic data with the following command:\n",
    "```bash\n",
    "singularity exec --nv ~/HEP-KBFI/singularity/base.simg python3 ../mlpf/tensorflow/delphes_model.py --action timing --weights weights.300-*.hdf5\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_data_d = json.load(open(\"synthetic_timing.json\", \"r\"))\n",
    "timing_data_d = sum(timing_data_d, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_data = pandas.DataFrame.from_records(timing_data_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = timing_data[timing_data[\"batch_size\"] == 1]\n",
    "times_b1 = lines.groupby(\"event_size\").apply(lambda x: np.mean(x[\"time_per_event\"]))\n",
    "\n",
    "\n",
    "lines = timing_data[timing_data[\"event_size\"] == 128*50]\n",
    "times_ev1 = lines.groupby(\"batch_size\").apply(lambda x: np.mean(x[\"time_per_event\"]))\n",
    "\n",
    "lines = timing_data[timing_data[\"event_size\"] == 128*20]\n",
    "times_ev2 = lines.groupby(\"batch_size\").apply(lambda x: np.mean(x[\"time_per_event\"]))\n",
    "\n",
    "lines = timing_data[timing_data[\"event_size\"] == 128*10]\n",
    "times_ev3 = lines.groupby(\"batch_size\").apply(lambda x: np.mean(x[\"time_per_event\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 2*8))\n",
    "\n",
    "bins = [128*10, 128*20, 128*30, 128*40, 128*50, 128*60, 128*70, 128*80, 128*90, 128*100]\n",
    "ax1.plot(times_b1.keys(), times_b1.values, marker=\"o\", label=\"MLPF\",lw=2,markersize=10)\n",
    "ax1.axvline(128*50, color=\"black\", ymin=0, ymax=0.39, lw=2,ls='--')\n",
    "#ax1.set_xticks(bins)\n",
    "\n",
    "#ax1.set_xticklabels([128*10, 128*20, 128*40, 128*80, 128*160])\n",
    "ax1.text(128*50*1.02, 10, r\"$t\\overline{t}$, 14 TeV, 200 PU\")\n",
    "ax1.set_ylim(0,120)\n",
    "#plt.xlim(0,25000)\n",
    "ax1.set_xlabel(\"Average event size [elements]\")\n",
    "ax1.set_ylabel(\"Average runtime / event [ms]\")\n",
    "ax1.legend(loc=\"best\", frameon=False)\n",
    "\n",
    "ax2.plot(times_ev3.keys(), times_ev3.values / times_ev3.values[0], marker=\"o\", label=\"40 PU\",lw=2,markersize=10)\n",
    "ax2.plot(times_ev2.keys(), times_ev2.values / times_ev2.values[0], marker=\"^\", label=\"80 PU\",lw=2,markersize=10)\n",
    "ax2.plot(times_ev1.keys(), times_ev1.values / times_ev1.values[0], marker=\"v\", label=\"200 PU\",lw=2,markersize=10)\n",
    "ax2.set_xticks([1, 2, 3, 4])\n",
    "ax2.set_xlabel(\"Batch size [events]\")\n",
    "ax2.set_ylabel(\"Relative inference time [a.u.]\")\n",
    "ax2.legend(loc=\"best\", frameon=False)\n",
    "\n",
    "plt.savefig(\"plots/inference_time.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TPR/FPR plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "ygen2 = fi[\"ygen\"]\n",
    "ycand2 = fi[\"ycand\"]\n",
    "ypred2 = fi[\"ypred\"]\n",
    "ypred_raw2 = fi[\"ypred_raw\"]\n",
    "ypred_sm2 = scipy.special.softmax(ypred_raw2, axis=-1)\n",
    "\n",
    "X2 = fi[\"X\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = 2\n",
    "preds = ypred_sm2[:, :, pid].flatten()\n",
    "msk_true = (ygen2[:, :, 0] == pid).flatten()\n",
    "msk_cand = (ycand2[:, :, 0] == pid).flatten()\n",
    "\n",
    "tpr_delphes = np.sum((msk_cand==True) & (msk_true==True)) /  np.sum(msk_true==True)\n",
    "fpr_delphes = np.sum((msk_cand==True) & (msk_true==False)) /  np.sum(msk_cand==True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "fpr, tpr, thresh = sklearn.metrics.roc_curve(msk_true, preds)\n",
    "plt.plot(fpr_delphes, tpr_delphes, marker=\"^\", label=\"Rule-based PF\", lw=0)\n",
    "plt.plot(fpr, tpr, label=\"MLPF\")\n",
    "plt.xlim(0.0, 0.25)\n",
    "plt.ylim(0.8,1.0)\n",
    "plt.xlabel(\"Fake rate\")\n",
    "plt.ylabel(\"Efficiency\")\n",
    "plt.title(\"MLPF classifier output for {}\".format(pid_names[pid]))\n",
    "plt.legend(loc=\"best\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
